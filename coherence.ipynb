{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=124\n",
    "n=100\n",
    "\n",
    "b = np.arange(0,t)\n",
    "a = np.arange(0,t)\n",
    "\n",
    "A=[]\n",
    "for i in range(n):\n",
    "    while True:\n",
    "        np.random.shuffle(a)\n",
    "        c = b-a\n",
    "        if not np.any(c == 0):\n",
    "            A.append(a)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=5\n",
    "\n",
    "from itertools import permutations\n",
    "c= list(permutations(np.arange(0,t), 2))\n",
    "\n",
    "a = np.asarray(c)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 2],\n",
       "       [0, 3],\n",
       "       [0, 4],\n",
       "       [1, 0],\n",
       "       [1, 2],\n",
       "       [1, 3],\n",
       "       [1, 4],\n",
       "       [2, 0],\n",
       "       [2, 1],\n",
       "       [2, 3],\n",
       "       [2, 4],\n",
       "       [3, 0],\n",
       "       [3, 1],\n",
       "       [3, 2],\n",
       "       [3, 4],\n",
       "       [4, 0],\n",
       "       [4, 1],\n",
       "       [4, 2],\n",
       "       [4, 3]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (0) into shape (5,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-214-29889a6d73fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mB\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (0) into shape (5,2)"
     ]
    }
   ],
   "source": [
    "B=np.zeros((10,t,2))\n",
    "for j in range(10):\n",
    "    A=[]\n",
    "    for i in range(t):\n",
    "        b = np.where(a[:,0]==i)\n",
    "        if not len(b[0]) == 0:\n",
    "            A.append(a[b[0][0],:])\n",
    "            a = np.delete(a, b[0][0], 0)\n",
    "    A = np.asarray(A)\n",
    "    \n",
    "    B[j,:,:]=A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1.],\n",
       "        [1., 0.],\n",
       "        [2., 0.],\n",
       "        [3., 0.],\n",
       "        [4., 0.]],\n",
       "\n",
       "       [[0., 2.],\n",
       "        [1., 2.],\n",
       "        [2., 1.],\n",
       "        [3., 1.],\n",
       "        [4., 1.]],\n",
       "\n",
       "       [[0., 3.],\n",
       "        [1., 3.],\n",
       "        [2., 3.],\n",
       "        [3., 2.],\n",
       "        [4., 2.]],\n",
       "\n",
       "       [[0., 4.],\n",
       "        [1., 4.],\n",
       "        [2., 4.],\n",
       "        [3., 4.],\n",
       "        [4., 3.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A=[]\n",
    "for i in range(t):\n",
    "    b = np.where(a[:,0]==i)\n",
    "    if not len(b[0]) == 0:\n",
    "        A.append(a[b[0][0],:])\n",
    "        a = np.delete(a, b[0][0], 0)\n",
    "A = np.asarray(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7625, 2)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "b = np.where(a[:,0]==i)\n",
    "a = np.delete(a, b[0][0], 0)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 70,  48,  88,  74,  40,  35,  47,  92,  90,   4,  54,  64,  91,\n",
       "       106,  46,  45,  19,  20,  28,  49,   6,  71, 121,  96, 117,  83,\n",
       "        12,  89, 101,   8, 105,   9,  38,  41,   3,   2,  99,  10, 114,\n",
       "       104,  78, 116,  63,  97,   1,  24,  33,  59, 107,  53,  51,  26,\n",
       "        17,  50,  77, 113,  95, 119,  21, 118, 102, 110,  43,  75,  84,\n",
       "       100,  36,  93,  80, 103,  61,  52,  23, 109,  87,  60,  11,  65,\n",
       "       115,  81,   0,  22, 120,  31,  32,  37,  85,  68,  76,  82,  25,\n",
       "        15,  67,  55, 112, 108,  30,  72,  66,  34,  14,  62,  58,  56,\n",
       "        27,  73,  44,  42,  13,  98,  86,  39, 123,   7,  69,  29,   5,\n",
       "        16, 122,  94,  57,  18, 111,  79])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(0,3)\n",
    "b = np.arange(0,3)\n",
    "c = [list(zip(a, p)) for p in permutations(b)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ndarray(shape=(124,2),dtype=int)\n",
    "a[:,0] = np.arange(0,124)\n",
    "a[:,1] = np.arange(0,124)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "import os\n",
    "import scipy.io\n",
    "import listen_italian_functions\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "\n",
    "data_path = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "\n",
    "subject_name = ['Alice','Andrea','Daniel','Elena','Elenora','Elisa','Federica','Francesca','Gianluca1','Giada','Giorgia',\n",
    "                'Jonluca','Laura','Leonardo','Linda','Lucrezia','Manu','Marco','Martina','Pagani','Pasquale','Sara',\n",
    "                'Silvia','Silvia2','Tommaso']\n",
    "#subject_name = ['Alice','Andrea','Daniel','Elena','Elenora','Elisa','Federica','Francesca','Gianluca1','Giada','Giorgia',\n",
    "#                'Jonluca','Laura','Leonardo','Linda','Lucrezia','Manu','Marco','Martina','Pagani','Pasquale',\n",
    "#                'Silvia','Silvia2','Tommaso']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# epoching and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract trials of tmax second and remove the wrong answer trials and seperate them in three conditions\n",
    "Tmin = 0\n",
    "Tmax = 3.51\n",
    "trial_len = 2\n",
    "\n",
    "for s in subject_name:\n",
    "    raw_fname = data_path + '/python/data/'+s+'_raw.fif'\n",
    "    raw = mne.io.read_raw_fif(raw_fname,preload=True)\n",
    "    raw_fname = data_path + '/behaviour/data/subject/'+s+'_behaviour.mat'\n",
    "    mat = scipy.io.loadmat(raw_fname)\n",
    "    epochs = listen_italian_functions.epoch(raw, mat,Tmin, Tmax)\n",
    "    save_path = data_path + '/python/data/coherence_epochs/'+s+'-coh-epo-'+str(Tmin)+'-'+str(Tmax)+'-trialLen-'+str(trial_len)+'.fif'\n",
    "    epochs.save(save_path)\n",
    "    print('----------------------------------------------------------------------------------------------------------------'+s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the epoches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Tmin = 0\n",
    "Tmax = 3.51\n",
    "trial_len = 2\n",
    "\n",
    "GA_epoches = []\n",
    "for s in subject_name:\n",
    "    save_path = data_path + '/python/data/coherence_epochs/'+s+'-coh-epo-'+str(Tmin)+'-' \\\n",
    "    +str(Tmax)+'-trialLen-'+str(trial_len)+'.fif'\n",
    "    epochs = mne.read_epochs(save_path)\n",
    "    GA_epoches.append(epochs)\n",
    "    print('----------------------------------------------------------------------------------------------------------------'+s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "condition = ['Hyper','Normal','Hypo']\n",
    "frames = []\n",
    "for s in range(0,len(subject_name)):\n",
    "    df = pd.DataFrame({'Condition':'Hyper','Subject':subject_name[s],'noTrials':GA_epoches[s]['hyper'].get_data().shape[0]},index=[s])\n",
    "    df = df.append(pd.DataFrame({'Condition':'Normal','Subject':subject_name[s],'noTrials':GA_epoches[s]['normal'].get_data().shape[0]},index=[s]))\n",
    "    df = df.append(pd.DataFrame({'Condition':'Hypo','Subject':subject_name[s],'noTrials':GA_epoches[s]['hypo'].get_data().shape[0]},index=[s]))\n",
    "    frames.append(df)\n",
    "    \n",
    "data=pd.concat((frames),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=data.groupby(['Subject','Condition']).sum()['noTrials'].unstack().plot(kind='bar',figsize=(20,5),grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring the coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "remove_first = 0.5 #seconds\n",
    "\n",
    "# let's explore some frequency bands\n",
    "iter_freqs = [\n",
    "    ('Delta', 1, 3),\n",
    "    ('Theta', 4, 7),\n",
    "    ('Alpha', 8, 12),\n",
    "    ('Beta', 13, 25),\n",
    "    ('Gamma', 30, 40)\n",
    "]\n",
    "\n",
    "iter_freqs = [\n",
    "    ('fr', 1, 3),\n",
    "    #('fr', 2, 4),\n",
    "    #('fr', 3, 5),\n",
    "    ('fr', 4, 6)\n",
    "    #('fr', 5, 7),\n",
    "    #('fr', 6, 8),\n",
    "    #('fr', 7, 9),\n",
    "    #('fr', 8, 10),\n",
    "    #('fr', 9, 11),\n",
    "    #('fr', 10, 12)\n",
    "]\n",
    "features = ['envelop','jawaopening','lipaparature','lipProtrusion','TTCD','TMCD','TBCD']\n",
    "condition = ['Hyper','Normal','Hypo', 'All']\n",
    "condition_dummy = ['hyper','normal','hypo']\n",
    "\n",
    "delay = np.arange(0,1.1,0.1)\n",
    "\n",
    "\n",
    "indices = (np.repeat([np.arange(59,len(features)+59)],59),np.tile(np.arange(0,59),len(features)))   \n",
    "\n",
    "extra_channels = ['envelop','jawaopening','lipaparature','lipProtrusion','TTCD','TMCD','TBCD']\n",
    "eeg_channles = np.setdiff1d(GA_epoches[0].ch_names, extra_channels)\n",
    "event_id = {'Hyper': 1,'Normal': 2,'Hypo': 3}\n",
    "ch_types = np.repeat('eeg', len(features)+59)\n",
    "ch_names = np.hstack((eeg_channles,features))        \n",
    "info = mne.create_info(ch_names = ch_names.tolist(),ch_types = ch_types,sfreq = GA_epoches[0].info['sfreq'])\n",
    "ch_names = np.setdiff1d(extra_channels,features)\n",
    "        \n",
    "for s in range(0,len(subject_name)):\n",
    "    frames = []\n",
    "    for d in delay:        \n",
    "\n",
    "        Ocoh = listen_italian_functions.coherence_preprocess_delay(GA_epoches[s],remove_first,d,trial_len,\n",
    "                                                                        extra_channels,eeg_channles,\n",
    "                                                                        info,ch_names,event_id,iter_freqs,indices,condition)\n",
    "\n",
    "            \n",
    "            \n",
    "        for i in range(0,len(condition)):\n",
    "            # mean or median of the surrogate distribution\n",
    "            coh=Ocoh[:,:,i]\n",
    "            for fr in range(0,len(iter_freqs)):\n",
    "                a = str(iter_freqs[fr][0])+ ' '+str(iter_freqs[fr][1])+' - '+str(iter_freqs[fr][2])+'Hz'\n",
    "                cc = np.split(coh[:,fr], len(features))\n",
    "                for f in range(0,len(features)):\n",
    "                    feature = features[f]\n",
    "                    if condition[i] != 'All':\n",
    "                        df = pd.DataFrame({'Condition':condition[i],'Freq':a,'Delay':d,'Subject':subject_name[s],'Feature':feature,\n",
    "                                       'Data':[cc[f].flatten()],'noTrials':GA_epoches[s][condition_dummy[i]].get_data().shape[0],})\n",
    "                    else:\n",
    "                        df = pd.DataFrame({'Condition':condition[i],'Freq':a,'Delay':d,'Subject':subject_name[s],'Feature':feature,\n",
    "                                       'Data':[cc[f].flatten()],'noTrials':GA_epoches[s].get_data().shape[0],})\n",
    "\n",
    "            \n",
    "                    \n",
    "                    frames.append(df) \n",
    "    print(d)\n",
    "                \n",
    "    data=pd.concat((frames),axis=0)\n",
    "    save_path = data_path + '/python/data/1-12Hz_frequency_bands_in2hzStep_coherence/coherence-trialLen-'\\\n",
    "    +str(trial_len)+'-removedFirst-'+str(remove_first)+'s-'+subject_name[s]\n",
    "    data.to_pickle(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure the coherence in specific delay and shifting the eeg and speech from speech onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     27
    ]
   },
   "outputs": [],
   "source": [
    "remove_first = [0,0.1,0.2,0.3,0.4,0.5] #seconds\n",
    "\n",
    "for rf in remove_first:\n",
    "        # let's explore some frequency bands\n",
    "    iter_freqs = [\n",
    "        ('Delta', 1, 3),\n",
    "        ('Theta', 4, 7),\n",
    "        ('Alpha', 8, 12),\n",
    "        ('Beta', 13, 25),\n",
    "        ('Gamma', 30, 40)\n",
    "    ]\n",
    "    features = ['envelop','jawaopening','lipaparature','lipProtrusion','TTCD','TMCD','TBCD']\n",
    "    condition = ['Hyper','Normal','Hypo']\n",
    "    delay = np.arange(0,1.1,0.1)\n",
    "    delay = [0,0.1,0.2]\n",
    "    delay = np.add(delay,0.5) #shift to below algorithm format\n",
    "    indices = (np.repeat([np.arange(59,len(features)+59)],59),np.tile(np.arange(0,59),len(features)))  \n",
    "    extra_channels = ['envelop','jawaopening','lipaparature','lipProtrusion','TTCD','TMCD','TBCD']\n",
    "    eeg_channles = np.setdiff1d(GA_epoches[0].ch_names, extra_channels)\n",
    "    event_id = {'hyper': 1,'normal': 2,'hypo': 3}\n",
    "    ch_types = np.repeat('eeg', len(features)+59)\n",
    "    ch_names = np.hstack((eeg_channles,features))        \n",
    "    info = mne.create_info(ch_names = ch_names.tolist(),ch_types = ch_types,sfreq = GA_epoches[0].info['sfreq'])\n",
    "    ch_names = np.setdiff1d(extra_channels,features)\n",
    "\n",
    "    for s in tqdm_notebook(range(0,len(subject_name)), desc='Subjects'):\n",
    "        frames = []\n",
    "        for d in tqdm_notebook(delay, desc='Delay'):        \n",
    "\n",
    "            epoch = listen_italian_functions.coherence_preprocess_delay(GA_epoches[s],rf,d,trial_len,\n",
    "                                                                        extra_channels,eeg_channles,info,ch_names,event_id)\n",
    "\n",
    "\n",
    "            for band, fmin, fmax in iter_freqs:\n",
    "                a = band+ ' '+str(fmin)+' - '+str(fmax)+'Hz'                \n",
    "                hyper, freqs, times, n_epochs, n_tapers = listen_italian_functions.coherence_measure(epoch['hyper'],fmin, fmax,indices)\n",
    "                normal, freqs, times, n_epochs, n_tapers = listen_italian_functions.coherence_measure(epoch['normal'],fmin, fmax,indices)\n",
    "                hypo, freqs, times, n_epochs, n_tapers = listen_italian_functions.coherence_measure(epoch['hypo'],fmin, fmax,indices)\n",
    "                allC, freqs, times, n_epochs, n_tapers = listen_italian_functions.coherence_measure(epoch,fmin, fmax,indices)\n",
    "\n",
    "                hyper = np.split(hyper, len(features))\n",
    "                normal = np.split(normal, len(features))\n",
    "                hypo = np.split(hypo, len(features))\n",
    "                allC = np.split(allC, len(features))\n",
    "\n",
    "                for f in range(0,len(features)):\n",
    "                    feature = features[f]\n",
    "                    df = pd.DataFrame({'Condition':'Hyper','Freq':a,'Delay':d,'Feature':feature,\n",
    "                                               'noTrials':GA_epoches[s]['hyper'].get_data().shape[0],\n",
    "                                               'Subject':subject_name[s],'Data':[hyper[f].flatten()]})\n",
    "                    df = df.append(pd.DataFrame({'Condition':'Normal','Freq':a,'Delay':d,'Feature':feature,\n",
    "                                                 'noTrials':GA_epoches[s]['normal'].get_data().shape[0],\n",
    "                                                 'Subject':subject_name[s],'Data':[normal[f].flatten()]}))\n",
    "                    df = df.append(pd.DataFrame({'Condition':'Hypo','Freq':a,'Delay':d,'Feature':feature,\n",
    "                                                 'noTrials':GA_epoches[s]['hypo'].get_data().shape[0],\n",
    "                                                 'Subject':subject_name[s],'Data':[hypo[f].flatten()]}))\n",
    "                    df = df.append(pd.DataFrame({'Condition':'All','Freq':a,'Delay':d,'Feature':feature,\n",
    "                                                 'noTrials':GA_epoches[s].get_data().shape[0],\n",
    "                                                 'Subject':subject_name[s],'Data':[allC[f].flatten()]}))\n",
    "                    frames.append(df)\n",
    "            print(d)\n",
    "\n",
    "        data=pd.concat((frames),axis=0)\n",
    "        save_path = data_path + '/analysis/python/data/shift/coherence-trialLen-'+str(trial_len)+'-removedFirst-'+str(rf)+'s-'+subject_name[s]\n",
    "        data.to_pickle(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapping and creating a surrogate distribution for each subject. substract the average of the distribution from the original coherence value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "no_surrogates = 100\n",
    "remove_first = 0.5 #seconds\n",
    "iter_freqs = [\n",
    "    ('fr', 1, 3),\n",
    "    ('fr', 4, 6)\n",
    "]\n",
    "features = ['envelop','jawaopening','lipaparature','lipProtrusion','TTCD','TMCD','TBCD']\n",
    "delay = np.arange(0,1.1,0.1)\n",
    "\n",
    "\n",
    "\n",
    "indices = (np.repeat([np.arange(59,len(features)+59)],59),np.tile(np.arange(0,59),len(features)))  \n",
    "extra_channels = ['envelop','jawaopening','lipaparature','lipProtrusion','TTCD','TMCD','TBCD']\n",
    "eeg_channles = np.setdiff1d(GA_epoches[0].ch_names, extra_channels)\n",
    "event_id = {'hyper': 1,'normal': 2,'hypo': 3}\n",
    "ch_types = np.repeat('eeg', len(features)+59)\n",
    "ch_names = np.hstack((eeg_channles,features))        \n",
    "info = mne.create_info(ch_names = ch_names.tolist(),ch_types = ch_types,sfreq = GA_epoches[0].info['sfreq'])\n",
    "ch_names = np.setdiff1d(extra_channels,features)\n",
    "    \n",
    "for s in range(0,len(subject_name)):\n",
    "    frames = []\n",
    "    for d in delay:       \n",
    "        surrogate_coh = listen_italian_functions.coherence_preprocess_delay_surrogate(GA_epoches[s],remove_first,\n",
    "                                                                                      d,trial_len,extra_channels,\n",
    "                                                                                      eeg_channles,info,ch_names,\n",
    "                                                                                      event_id,no_surrogates,\n",
    "                                                                                      iter_freqs,indices)\n",
    "        \n",
    "        # mean or median of the surrogate distribution\n",
    "        coh=surrogate_coh.mean(axis=2)\n",
    "        \n",
    "        for fr in range(0,len(iter_freqs)):\n",
    "            a = str(iter_freqs[fr][0])+ ' '+str(iter_freqs[fr][1])+' - '+str(iter_freqs[fr][2])+'Hz'\n",
    "            cc = np.split(coh[:,fr], len(features))\n",
    "            for f in range(0,len(features)):\n",
    "                feature = features[f]\n",
    "                df = pd.DataFrame({'Condition':'All','Freq':a,'Delay':d,'Subject':subject_name[s],'Feature':feature,\n",
    "                                   'Surrogate':[cc[f].flatten()]})\n",
    "                frames.append(df)                \n",
    "    data=pd.concat((frames),axis=0)\n",
    "    save_path = data_path + '/python/data/SurrogateCoherence/SurrogateCoherence-trialLen-'+str(trial_len)+'-removedFirst-'\\\n",
    "    +str(remove_first)+'s-'+subject_name[s]\n",
    "    data.to_pickle(save_path)     \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay = np.arange(0.5,1,0.1)\n",
    "delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putit into one file\n",
    "save_path = data_path + '/python/data/SurrogateCoherence/SurrogateCoherence-trialLen-'+str(trial_len)+'-removedFirst-'\\\n",
    "    +str(remove_first)+'s'\n",
    "\n",
    "frames = []\n",
    "for s in subject_name:    \n",
    "    frames.append(pd.read_pickle(save_path+'-'+s))\n",
    "    \n",
    "data = pd.concat((frames),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
