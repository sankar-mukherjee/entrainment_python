{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import os\n",
    "import scipy.io\n",
    "import listen_italian_functions\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import clear_output\n",
    "from itertools import combinations,permutations\n",
    "from IPython.display import clear_output\n",
    "\n",
    "data_path = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "\n",
    "subject_name = ['Alice','Andrea','Daniel','Elena','Elenora','Elisa','Federica','Francesca','Gianluca1','Giada','Giorgia',\n",
    "                'Jonluca','Laura','Leonardo','Linda','Lucrezia','Manu','Marco','Martina','Pagani','Pasquale','Sara',\n",
    "                'Silvia','Silvia2','Tommaso']\n",
    "\n",
    "remove_first = 0.5 #seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the epoches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This filename (C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Alice-coh-epo-0-3.51-trialLen-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif or -epo.fif.gz\n",
      "Reading C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Alice-coh-epo-0-3.51-trialLen-2.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    3507.50 ms\n",
      "        0 CTF compensation matrices available\n",
      "124 matching events found\n",
      "No baseline correction applied\n",
      "124 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "----------------------------------------------------------------------------------------------------------------Alice\n",
      "This filename (C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Andrea-coh-epo-0-3.51-trialLen-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif or -epo.fif.gz\n",
      "Reading C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Andrea-coh-epo-0-3.51-trialLen-2.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    3507.50 ms\n",
      "        0 CTF compensation matrices available\n",
      "121 matching events found\n",
      "No baseline correction applied\n",
      "121 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "----------------------------------------------------------------------------------------------------------------Andrea\n",
      "This filename (C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Daniel-coh-epo-0-3.51-trialLen-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif or -epo.fif.gz\n",
      "Reading C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Daniel-coh-epo-0-3.51-trialLen-2.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    3507.50 ms\n",
      "        0 CTF compensation matrices available\n",
      "122 matching events found\n",
      "No baseline correction applied\n",
      "122 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "----------------------------------------------------------------------------------------------------------------Daniel\n",
      "This filename (C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Elena-coh-epo-0-3.51-trialLen-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif or -epo.fif.gz\n",
      "Reading C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Elena-coh-epo-0-3.51-trialLen-2.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    3507.50 ms\n",
      "        0 CTF compensation matrices available\n",
      "121 matching events found\n",
      "No baseline correction applied\n",
      "121 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "----------------------------------------------------------------------------------------------------------------Elena\n",
      "This filename (C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Elenora-coh-epo-0-3.51-trialLen-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif or -epo.fif.gz\n",
      "Reading C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Elenora-coh-epo-0-3.51-trialLen-2.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    3507.50 ms\n",
      "        0 CTF compensation matrices available\n",
      "122 matching events found\n",
      "No baseline correction applied\n",
      "122 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "----------------------------------------------------------------------------------------------------------------Elenora\n",
      "This filename (C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Elisa-coh-epo-0-3.51-trialLen-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif or -epo.fif.gz\n",
      "Reading C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Elisa-coh-epo-0-3.51-trialLen-2.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    3507.50 ms\n",
      "        0 CTF compensation matrices available\n",
      "114 matching events found\n",
      "No baseline correction applied\n",
      "114 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "----------------------------------------------------------------------------------------------------------------Elisa\n",
      "This filename (C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Federica-coh-epo-0-3.51-trialLen-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif or -epo.fif.gz\n",
      "Reading C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Federica-coh-epo-0-3.51-trialLen-2.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    3507.50 ms\n",
      "        0 CTF compensation matrices available\n",
      "119 matching events found\n",
      "No baseline correction applied\n",
      "119 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "----------------------------------------------------------------------------------------------------------------Federica\n",
      "This filename (C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Francesca-coh-epo-0-3.51-trialLen-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif or -epo.fif.gz\n",
      "Reading C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Francesca-coh-epo-0-3.51-trialLen-2.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    3507.50 ms\n",
      "        0 CTF compensation matrices available\n",
      "119 matching events found\n",
      "No baseline correction applied\n",
      "119 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "----------------------------------------------------------------------------------------------------------------Francesca\n",
      "This filename (C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Gianluca1-coh-epo-0-3.51-trialLen-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif or -epo.fif.gz\n",
      "Reading C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Gianluca1-coh-epo-0-3.51-trialLen-2.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    3507.50 ms\n",
      "        0 CTF compensation matrices available\n",
      "120 matching events found\n",
      "No baseline correction applied\n",
      "120 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "----------------------------------------------------------------------------------------------------------------Gianluca1\n",
      "This filename (C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Giada-coh-epo-0-3.51-trialLen-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif or -epo.fif.gz\n",
      "Reading C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Giada-coh-epo-0-3.51-trialLen-2.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    3507.50 ms\n",
      "        0 CTF compensation matrices available\n",
      "121 matching events found\n",
      "No baseline correction applied\n",
      "121 matching events found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "----------------------------------------------------------------------------------------------------------------Giada\n",
      "This filename (C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Giorgia-coh-epo-0-3.51-trialLen-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif or -epo.fif.gz\n",
      "Reading C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Giorgia-coh-epo-0-3.51-trialLen-2.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    3507.50 ms\n",
      "        0 CTF compensation matrices available\n",
      "121 matching events found\n",
      "No baseline correction applied\n",
      "121 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "----------------------------------------------------------------------------------------------------------------Giorgia\n",
      "This filename (C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Jonluca-coh-epo-0-3.51-trialLen-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif or -epo.fif.gz\n",
      "Reading C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Jonluca-coh-epo-0-3.51-trialLen-2.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    3507.50 ms\n",
      "        0 CTF compensation matrices available\n",
      "110 matching events found\n",
      "No baseline correction applied\n",
      "110 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "----------------------------------------------------------------------------------------------------------------Jonluca\n",
      "This filename (C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Laura-coh-epo-0-3.51-trialLen-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif or -epo.fif.gz\n",
      "Reading C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Laura-coh-epo-0-3.51-trialLen-2.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    3507.50 ms\n",
      "        0 CTF compensation matrices available\n",
      "120 matching events found\n",
      "No baseline correction applied\n",
      "120 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "----------------------------------------------------------------------------------------------------------------Laura\n",
      "This filename (C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Leonardo-coh-epo-0-3.51-trialLen-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif or -epo.fif.gz\n",
      "Reading C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Leonardo-coh-epo-0-3.51-trialLen-2.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    3507.50 ms\n",
      "        0 CTF compensation matrices available\n",
      "119 matching events found\n",
      "No baseline correction applied\n",
      "119 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "----------------------------------------------------------------------------------------------------------------Leonardo\n",
      "This filename (C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Linda-coh-epo-0-3.51-trialLen-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif or -epo.fif.gz\n",
      "Reading C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Linda-coh-epo-0-3.51-trialLen-2.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    3507.50 ms\n",
      "        0 CTF compensation matrices available\n",
      "114 matching events found\n",
      "No baseline correction applied\n",
      "114 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "----------------------------------------------------------------------------------------------------------------Linda\n",
      "This filename (C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Lucrezia-coh-epo-0-3.51-trialLen-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif or -epo.fif.gz\n",
      "Reading C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Lucrezia-coh-epo-0-3.51-trialLen-2.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    3507.50 ms\n",
      "        0 CTF compensation matrices available\n",
      "123 matching events found\n",
      "No baseline correction applied\n",
      "123 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "----------------------------------------------------------------------------------------------------------------Lucrezia\n",
      "This filename (C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Manu-coh-epo-0-3.51-trialLen-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif or -epo.fif.gz\n",
      "Reading C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Manu-coh-epo-0-3.51-trialLen-2.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    3507.50 ms\n",
      "        0 CTF compensation matrices available\n",
      "120 matching events found\n",
      "No baseline correction applied\n",
      "120 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "----------------------------------------------------------------------------------------------------------------Manu\n",
      "This filename (C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Marco-coh-epo-0-3.51-trialLen-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif or -epo.fif.gz\n",
      "Reading C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Marco-coh-epo-0-3.51-trialLen-2.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    3507.50 ms\n",
      "        0 CTF compensation matrices available\n",
      "114 matching events found\n",
      "No baseline correction applied\n",
      "114 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "----------------------------------------------------------------------------------------------------------------Marco\n",
      "This filename (C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Martina-coh-epo-0-3.51-trialLen-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif or -epo.fif.gz\n",
      "Reading C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Martina-coh-epo-0-3.51-trialLen-2.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    3507.50 ms\n",
      "        0 CTF compensation matrices available\n",
      "123 matching events found\n",
      "No baseline correction applied\n",
      "123 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "----------------------------------------------------------------------------------------------------------------Martina\n",
      "This filename (C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Pagani-coh-epo-0-3.51-trialLen-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif or -epo.fif.gz\n",
      "Reading C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Pagani-coh-epo-0-3.51-trialLen-2.fif ...\n",
      "Isotrak not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =       0.00 ...    3507.50 ms\n",
      "        0 CTF compensation matrices available\n",
      "122 matching events found\n",
      "No baseline correction applied\n",
      "122 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "----------------------------------------------------------------------------------------------------------------Pagani\n",
      "This filename (C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Pasquale-coh-epo-0-3.51-trialLen-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif or -epo.fif.gz\n",
      "Reading C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Pasquale-coh-epo-0-3.51-trialLen-2.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    3507.50 ms\n",
      "        0 CTF compensation matrices available\n",
      "117 matching events found\n",
      "No baseline correction applied\n",
      "117 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "----------------------------------------------------------------------------------------------------------------Pasquale\n",
      "This filename (C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Sara-coh-epo-0-3.51-trialLen-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif or -epo.fif.gz\n",
      "Reading C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Sara-coh-epo-0-3.51-trialLen-2.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    3507.50 ms\n",
      "        0 CTF compensation matrices available\n",
      "120 matching events found\n",
      "No baseline correction applied\n",
      "120 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "----------------------------------------------------------------------------------------------------------------Sara\n",
      "This filename (C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Silvia-coh-epo-0-3.51-trialLen-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif or -epo.fif.gz\n",
      "Reading C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Silvia-coh-epo-0-3.51-trialLen-2.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    3507.50 ms\n",
      "        0 CTF compensation matrices available\n",
      "120 matching events found\n",
      "No baseline correction applied\n",
      "120 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "----------------------------------------------------------------------------------------------------------------Silvia\n",
      "This filename (C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Silvia2-coh-epo-0-3.51-trialLen-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif or -epo.fif.gz\n",
      "Reading C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Silvia2-coh-epo-0-3.51-trialLen-2.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    3507.50 ms\n",
      "        0 CTF compensation matrices available\n",
      "118 matching events found\n",
      "No baseline correction applied\n",
      "118 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "----------------------------------------------------------------------------------------------------------------Silvia2\n",
      "This filename (C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Tommaso-coh-epo-0-3.51-trialLen-2.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif or -epo.fif.gz\n",
      "Reading C:\\Users\\SMukherjee\\Desktop\\projects\\listen_italian_motor_entrainment\\analysis/python/data/coherence_epochs/Tommaso-coh-epo-0-3.51-trialLen-2.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    3507.50 ms\n",
      "        0 CTF compensation matrices available\n",
      "121 matching events found\n",
      "No baseline correction applied\n",
      "121 matching events found\n",
      "No baseline correction applied\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "----------------------------------------------------------------------------------------------------------------Tommaso\n"
     ]
    }
   ],
   "source": [
    "Tmin = 0\n",
    "Tmax = 3.51\n",
    "trial_len = 2\n",
    "\n",
    "GA_epoches = []\n",
    "for s in subject_name:\n",
    "    save_path = data_path + '/python/data/coherence_epochs/'+s+'-coh-epo-'+str(Tmin)+'-' \\\n",
    "    +str(Tmax)+'-trialLen-'+str(trial_len)+'.fif'\n",
    "    epochs = mne.read_epochs(save_path)\n",
    "    GA_epoches.append(epochs)\n",
    "    print('----------------------------------------------------------------------------------------------------------------'+s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# partial coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coherence\n",
    "<img src=\"http://nipy.org/nitime/_images/math/8b2ad8f5230194bf1f946cdde75e57e513e8fb18.png\">\n",
    "\n",
    "partial coherence\n",
    "<img src=\"http://nipy.org/nitime/_images/math/6f19a896ad7872e2077078e1d5dc1bac04b2049c.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     22,
     30
    ]
   },
   "outputs": [],
   "source": [
    "def coherence_preprocess_delay(epochs,remove_first,d,trial_len,extra_channels,eeg_channles,condition):\t\n",
    "\n",
    "    if condition != 'All':\n",
    "        E = epochs[condition].copy()\n",
    "    else:\n",
    "        E = epochs.copy()\n",
    "        \n",
    "    eeg = E.copy().pick_channels(eeg_channles)\n",
    "    speech = E.copy().pick_channels(extra_channels)\n",
    "\n",
    "    E = eeg.copy().crop(d+remove_first,d+remove_first+trial_len)\n",
    "    S = speech.copy().crop(0.5+remove_first,0.5+remove_first+trial_len)\n",
    "    \n",
    "    #E = eeg.copy().crop(0.5+remove_first,0.5+remove_first+trial_len)\n",
    "    #S = speech.copy().crop(d+remove_first,d+remove_first+trial_len)\n",
    "    \n",
    "    \n",
    "    c = np.concatenate((E.get_data(),S.get_data()),axis=1)\n",
    "    \n",
    "    return c\n",
    "\n",
    "\n",
    "def get_coherence(epochs,sfreq,fmin,fmax,indices):\n",
    "    con, freqs, times, n_epochs, n_tapers = mne.connectivity.spectral_connectivity(epochs, method='coh',mode='multitaper', \n",
    "                                                                                   sfreq=sfreq, \n",
    "                                                              fmin=fmin, fmax=fmax,indices=indices,faverage=True, \n",
    "                                                              tmin=0, mt_adaptive=False, block_size=1000,verbose='ERROR')\n",
    "\n",
    "    return con\n",
    "\n",
    "def get_partialCoherence(conXY,conXR,conRY,fr):\n",
    "    partial_coh_XY_R=[]\n",
    "    for i in range(59):\n",
    "        a = (abs(conXY[i,fr]-conXR[i,fr]*conRY[fr])**2) / ((1-abs(conXR[i,fr])**2)*(1-abs(conRY[fr])**2))\n",
    "        partial_coh_XY_R.append(a)\n",
    "\n",
    "    partial_coh_XY_R = np.asarray(partial_coh_XY_R)\n",
    "    \n",
    "    return partial_coh_XY_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     28,
     43,
     53
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = ['envelop','jawaopening','lipaparature','lipProtrusion','TTCD','TMCD','TBCD']\n",
    "eeg_chan = GA_epoches[0].ch_names[0:59]\n",
    "sfreq = GA_epoches[0].info['sfreq']\n",
    "\n",
    "delay = np.arange(-5,6) / 10\n",
    "\n",
    "condition = ['hyper','normal','hypo','All']\n",
    "condition = ['All']\n",
    "\n",
    "features = ['envelop','lipaparature']\n",
    "\n",
    "feat_comb = (['envelop','lipaparature'],['lipaparature','envelop'])\n",
    "\n",
    "#############################\n",
    "iter_freqs = [\n",
    "    ('fr', 0.25, 1),\n",
    "    ('fr', 0.5, 2),\n",
    "    ('fr', 1, 3),\n",
    "    ('fr', 1, 4),\n",
    "    ('fr', 2, 6),\n",
    "    ('fr', 4, 8),\n",
    "    ('fr', 8, 12),\n",
    "    ('fr', 12, 18),\n",
    "    ('fr', 18, 24),\n",
    "    ('fr', 24, 40)\n",
    "]\n",
    "fmin = []\n",
    "fmax = []\n",
    "for fr in range(0,len(iter_freqs)):\n",
    "    fmin.append(iter_freqs[fr][1])\n",
    "    fmax.append(iter_freqs[fr][2])\n",
    "    \n",
    "#######################################\n",
    "indices = []\n",
    "b = (np.repeat(59,59),np.arange(0,59))\n",
    "indices.append(b)\n",
    "b = (np.repeat(60,59),np.arange(0,59))\n",
    "indices.append(b)\n",
    "b = (np.repeat(59,1),np.repeat(60,1))\n",
    "indices.append(b)\n",
    "\n",
    "INDEX = []\n",
    "b=0\n",
    "for idx in range(0,len(indices)):\n",
    "    a = np.arange(b,b+len(indices[idx][0]))\n",
    "    INDEX.append(a)\n",
    "    b = b+len(a)\n",
    "\n",
    "indices = np.concatenate((indices),axis=1)\n",
    "indices = (indices[0],indices[1])\n",
    "#######################################    \n",
    "    \n",
    "frame = [] \n",
    "for s in range(0,len(subject_name)):\n",
    "    for d in delay:\n",
    "        for con in condition:\n",
    "            c = coherence_preprocess_delay(GA_epoches[s],remove_first,d + 0.5,trial_len,features,eeg_chan,con)         \n",
    "            coh = get_coherence(c,sfreq,fmin,fmax,indices)    \n",
    "\n",
    "            for iii in range(2):\n",
    "                if iii ==0:\n",
    "                    conXY = coh[INDEX[0],:]\n",
    "                    conXR = coh[INDEX[1],:]\n",
    "                else:\n",
    "                    conXY = coh[INDEX[1],:]\n",
    "                    conXR = coh[INDEX[0],:]\n",
    "\n",
    "                conRY = coh[INDEX[2],:][0]\n",
    "\n",
    "                for fr in range(0,len(iter_freqs)):\n",
    "                    a = str(iter_freqs[fr][0])+ ' '+str(iter_freqs[fr][1])+' - '+str(iter_freqs[fr][2])+'Hz'\n",
    "\n",
    "                    cc = get_partialCoherence(conXY,conXR,conRY,fr)            \n",
    "\n",
    "                    df = pd.DataFrame({'Feature':feat_comb[iii][0],'FeatureDelay':d,'RemoveFeature':feat_comb[iii][1],\n",
    "                                       'RemoveFeatureDelay':d,'Freq':a,'Condition':con,\n",
    "                                       'Subject': subject_name[s], 'Data':[cc.flatten()]})\n",
    "                    frame.append(df)\n",
    "\n",
    "\n",
    "            print(str(d)+'-'+subject_name[s])\n",
    "\n",
    "data=pd.concat((frame),axis=0)\n",
    "save_path = data_path + '/python/data/partialCoh/PartialCoh-removedFirst-'+str(remove_first)+'.pkl'\n",
    "data.to_pickle(save_path)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# surrogate distribution partial coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     101
    ]
   },
   "outputs": [],
   "source": [
    "def PartialCoherence_preprocess_delay_surrogate(epochs,remove_first,d,trial_len,eeg_channles,keep_feat,condition,iter_freqs):\t\n",
    "\n",
    "    \n",
    "    ##############\n",
    "    if condition != 'All':\n",
    "        E = epochs[condition].copy()\n",
    "    else:\n",
    "        E = epochs.copy()\n",
    "    \n",
    "    eeg = E.copy().pick_channels(eeg_channles)\n",
    "    speech = E.copy().pick_channels(keep_feat)\n",
    "\n",
    "    E = eeg.copy().crop(d+remove_first,d+remove_first+trial_len)\n",
    "    S = speech.copy().crop(0.5+remove_first,0.5+remove_first+trial_len)\n",
    "    \n",
    "    #E = eeg.copy().crop(0.5+remove_first,0.5+remove_first+trial_len)\n",
    "    #S = speech.copy().crop(d+remove_first,d+remove_first+trial_len)\n",
    "    \n",
    "    \n",
    "    sfreq = E.info['sfreq']\n",
    "    \n",
    "    E = E.get_data()\n",
    "    S = S.get_data()\n",
    "\n",
    "    label = np.concatenate((eeg.ch_names,speech.ch_names))\n",
    "    \n",
    "    ##################### all possible combination\n",
    "    trial_length=S.shape[0]\n",
    "    a = list(permutations(np.arange(0,trial_length), 2))\n",
    "    a = np.asarray(a)\n",
    "    X = np.arange(0,trial_length)\n",
    "\n",
    "    no_surrogates = 500 #dummy value\n",
    "    B=[]\n",
    "    for j in range(no_surrogates):\n",
    "        X = np.roll(X,1)\n",
    "        while True:\n",
    "            A,a = get_combinations(X,a)        \n",
    "            if A.shape[0] == trial_length:\n",
    "                B.append(A)\n",
    "                break\n",
    "            elif len(a)==0:\n",
    "                break\n",
    "            else:\n",
    "                X = np.roll(X,1)\n",
    "                print('.',end=' ')\n",
    "    \n",
    "    B = np.asarray(B)\n",
    "    no_surrogates = len(B)\n",
    "    \n",
    "    #######################################Ã \n",
    "    fmin = []\n",
    "    fmax = []\n",
    "    for fr in range(0,len(iter_freqs)):\n",
    "        fmin.append(iter_freqs[fr][1])\n",
    "        fmax.append(iter_freqs[fr][2])  \n",
    "    \n",
    "    #######################################\n",
    "    indices = []\n",
    "    b = (np.repeat(59,59),np.arange(0,59))\n",
    "    indices.append(b)\n",
    "    b = (np.repeat(60,59),np.arange(0,59))\n",
    "    indices.append(b)\n",
    "    b = (np.repeat(59,1),np.repeat(60,1))\n",
    "    indices.append(b)\n",
    "\n",
    "    INDEX = []\n",
    "    b=0\n",
    "    for idx in range(0,len(indices)):\n",
    "        a = np.arange(b,b+len(indices[idx][0]))\n",
    "        INDEX.append(a)\n",
    "        b = b+len(a)\n",
    "\n",
    "    indices = np.concatenate((indices),axis=1)\n",
    "    indices = (indices[0],indices[1])\n",
    "    #######################################  \n",
    "\n",
    "    frames = np.zeros((2,59,len(iter_freqs),no_surrogates))\n",
    "    for i in range(no_surrogates):\n",
    "        print('--------------------'+str(i))\n",
    "        EE = E.copy()\n",
    "        SS = S.copy()\n",
    "        c = np.concatenate((EE[B[i][:,0]],SS[B[i][:,1]]),axis=1)\n",
    "        \n",
    "        coh = get_coherence(c,sfreq,fmin,fmax,indices)\n",
    "        for iii in range(0,1):\n",
    "            if iii ==0:\n",
    "                conXY = coh[INDEX[0],:]\n",
    "                conXR = coh[INDEX[1],:]\n",
    "            else:\n",
    "                conXY = coh[INDEX[1],:]\n",
    "                conXR = coh[INDEX[0],:]\n",
    "            \n",
    "            conRY = coh[INDEX[2],:][0]\n",
    "\n",
    "            for f in range(0,len(iter_freqs)):\n",
    "                frames[iii,:,f,i] = get_partialCoherence(conXY,conXR,conRY,f)\n",
    "        clear_output()  \n",
    "        \n",
    "    return frames\n",
    "\n",
    "def get_combinations(X,a):\n",
    "    aa = a\n",
    "    A=[]\n",
    "    EEG = []\n",
    "    Speech = []\n",
    "    for i in range(0,len(X)):\n",
    "        b = np.where(a[:,0]==X[i])\n",
    "        if not len(b[0]) == 0:\n",
    "            for k in range(len(b[0])):\n",
    "                if not a[b[0][k],1] in Speech:\n",
    "                    A.append(a[b[0][k],:])\n",
    "                    EEG.append(a[b[0][k],0])\n",
    "                    Speech.append(a[b[0][k],1])\n",
    "                    a = np.delete(a, b[0][k], 0)\n",
    "                    break\n",
    "    if len(A) == len(X):                    \n",
    "        return np.asarray(A),a\n",
    "    else:\n",
    "        return np.asarray(A),aa\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "features = ['envelop','jawaopening','lipaparature','lipProtrusion','TTCD','TMCD','TBCD']\n",
    "eeg_chan = GA_epoches[0].ch_names[0:59]\n",
    "sfreq = GA_epoches[0].info['sfreq']\n",
    "\n",
    "delay = np.arange(-5,6) / 10\n",
    "\n",
    "condition = ['hyper','normal','hypo','All']\n",
    "condition = ['All']\n",
    "\n",
    "features = ['envelop','lipaparature']\n",
    "\n",
    "#############################\n",
    "iter_freqs = [\n",
    "    ('fr', 0.25, 1),\n",
    "    ('fr', 0.5, 2),\n",
    "    ('fr', 1, 3),\n",
    "    ('fr', 1, 4),\n",
    "    ('fr', 2, 6),\n",
    "    ('fr', 4, 8),\n",
    "    ('fr', 8, 12),\n",
    "    ('fr', 12, 18),\n",
    "    ('fr', 18, 24),\n",
    "    ('fr', 24, 40)\n",
    "]\n",
    "\n",
    "#######################################    \n",
    "    \n",
    "    \n",
    "for s in range(0,len(subject_name)):\n",
    "    frame = [] \n",
    "    for d in delay:       \n",
    "        for con in condition:\n",
    "            surrogate_coh = PartialCoherence_preprocess_delay_surrogate(GA_epoches[s],remove_first,\n",
    "                                                                        d + 0.5,trial_len,eeg_chan,features,\n",
    "                                                                        con,iter_freqs)\n",
    "\n",
    "            # mean or median of the surrogate distribution\n",
    "            coh=surrogate_coh\n",
    "\n",
    "            for fr in range(0,len(iter_freqs)):\n",
    "                a = str(iter_freqs[fr][0])+ ' '+str(iter_freqs[fr][1])+' - '+str(iter_freqs[fr][2])+'Hz'\n",
    "\n",
    "                cc = coh[0,:,fr,:]            \n",
    "                df = pd.DataFrame({'Feature':features[0],'FeatureDelay':d,'RemoveFeature':features[1],\n",
    "                               'RemoveFeatureDelay':d,'Freq':a,'Condition':con,\n",
    "                               'Subject': subject_name[s], 'Data':[cc]})\n",
    "                frame.append(df)\n",
    "                cc = coh[1,:,fr,:]            \n",
    "                df = pd.DataFrame({'Feature':features[1],'FeatureDelay':d,'RemoveFeature':features[0],\n",
    "                               'RemoveFeatureDelay':d,'Freq':a,'Condition':con,\n",
    "                               'Subject': subject_name[s], 'Data':[cc]})\n",
    "                frame.append(df)    \n",
    "\n",
    "        \n",
    "    data=pd.concat((frame),axis=0)\n",
    "    a = ('-').join(features)\n",
    "    save_path = data_path + '/python/data/partialCoh/Surrogate_PartialCoh-removedFirst-' \\\n",
    "    +str(remove_first)+'-'+a+'-'+subject_name[s]+'.pkl'\n",
    "    data.to_pickle(save_path)  \n",
    "    \n",
    "# putit into one file    \n",
    "A=[]\n",
    "a = ('-').join(features)\n",
    "for s in subject_name:\n",
    "    save_path = data_path + '/python/data/partialCoh/SurrogateCoherence-removedFirst-' \\\n",
    "    +str(remove_first)+'-'+a+'-'+s+'.pkl'\n",
    "    A.append(pd.read_pickle(save_path))\n",
    "\n",
    "data = pd.concat((A),axis=0)\n",
    "save_path = data_path + '/python/data/partialCoh/SurrogateCoherence-removedFirst-' \\\n",
    "    +str(remove_first)+'-'+a+'.pkl'  \n",
    "data.to_pickle(save_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove contribution of lipaperature from the envelop delayed version (partial coherence implemented here) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partialCoherence_preprocess_delay(epochs,remove_first,d,trial_len,feat,condition,typee):\t\n",
    "\n",
    "    if condition != 'All':\n",
    "        E = epochs[condition].copy()\n",
    "    else:\n",
    "        E = epochs.copy()\n",
    "    \n",
    "    S = E.copy().pick_channels(feat)\n",
    "    \n",
    "    if typee != 'eeg':\n",
    "        E = S.copy().crop(d+remove_first,d+remove_first+trial_len)\n",
    "    else:\n",
    "        E = S.copy().crop(0.5+remove_first,0.5+remove_first+trial_len)\n",
    "\n",
    "    c = E.get_data()\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = ['envelop','jawaopening','lipaparature','lipProtrusion','TTCD','TMCD','TBCD']\n",
    "eeg_chan = GA_epoches[0].ch_names[0:59]\n",
    "sfreq = GA_epoches[0].info['sfreq']\n",
    "\n",
    "delay = np.arange(-5,6) / 10\n",
    "\n",
    "condition = ['hyper','normal','hypo','All']\n",
    "condition = ['All']\n",
    "\n",
    "features = ['envelop','lipaparature']\n",
    "\n",
    "feat_comb = (['envelop','lipaparature'],['lipaparature','envelop'])\n",
    "FD = np.arange(-5,6) / 10 # keep feature delay\n",
    "RD = np.arange(-5,6) / 10 # remove feature delay\n",
    "\n",
    "#############################\n",
    "iter_freqs = [\n",
    "    ('fr', 1, 3),\n",
    "    ('fr', 4, 6)\n",
    "]\n",
    "fmin = []\n",
    "fmax = []\n",
    "for fr in range(0,len(iter_freqs)):\n",
    "    fmin.append(iter_freqs[fr][1])\n",
    "    fmax.append(iter_freqs[fr][2])\n",
    "    \n",
    "#######################################\n",
    "indices = []\n",
    "b = (np.repeat(59,59),np.arange(0,59))\n",
    "indices.append(b)\n",
    "b = (np.repeat(60,59),np.arange(0,59))\n",
    "indices.append(b)\n",
    "b = (np.repeat(59,1),np.repeat(60,1))\n",
    "indices.append(b)\n",
    "\n",
    "INDEX = []\n",
    "b=0\n",
    "for idx in range(0,len(indices)):\n",
    "    a = np.arange(b,b+len(indices[idx][0]))\n",
    "    INDEX.append(a)\n",
    "    b = b+len(a)\n",
    "\n",
    "indices = np.concatenate((indices),axis=1)\n",
    "indices = (indices[0],indices[1])\n",
    "#######################################  \n",
    "    \n",
    "frame = [] \n",
    "for s in range(0,len(subject_name)):   \n",
    "    clear_output() \n",
    "    for fd in FD:\n",
    "        for rd in RD:\n",
    "            for con in condition:\n",
    "                eeg = partialCoherence_preprocess_delay(GA_epoches[s],remove_first,fd + 0.5,trial_len,eeg_chan,con,'eeg')\n",
    "                speech = partialCoherence_preprocess_delay(GA_epoches[s],remove_first,fd + 0.5,trial_len,[features[0]],con,'speech')\n",
    "                lipaparature = partialCoherence_preprocess_delay(GA_epoches[s],remove_first,rd + 0.5,trial_len,[features[1]],con,'speech')\n",
    "\n",
    "                c = np.concatenate((eeg,speech,lipaparature),axis=1)\n",
    "                coh = get_coherence(c,sfreq,fmin,fmax,indices)\n",
    "\n",
    "                for iii in range(2):\n",
    "                    if iii ==0:\n",
    "                        conXY = coh[INDEX[0],:]\n",
    "                        conXR = coh[INDEX[1],:]\n",
    "                    else:\n",
    "                        conXY = coh[INDEX[1],:]\n",
    "                        conXR = coh[INDEX[0],:]\n",
    "\n",
    "                    conRY = coh[INDEX[2],:][0]\n",
    "\n",
    "                    for fr in range(0,len(iter_freqs)):\n",
    "                        a = str(iter_freqs[fr][0])+ ' '+str(iter_freqs[fr][1])+' - '+str(iter_freqs[fr][2])+'Hz'\n",
    "\n",
    "                        cc = get_partialCoherence(conXY,conXR,conRY,fr)            \n",
    "                        df = pd.DataFrame({'Feature':feat_comb[iii][0],'FeatureDelay':fd,'RemoveFeature':feat_comb[iii][1],\n",
    "                                       'RemoveFeatureDelay':rd,'Freq':a,'Condition':con,\n",
    "                                       'Subject': subject_name[s], 'Data':[cc.flatten()]})\n",
    "                        frame.append(df)    \n",
    "                print(str(fd)+'-'+str(rd)+'-'+subject_name[s])\n",
    "\n",
    "data=pd.concat((frame),axis=0)\n",
    "save_path = data_path + '/python/data/partialCoh/Delayed_partialCohopp-removedFirst-'+str(remove_first)+'.pkl'\n",
    "data.to_pickle(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=0\n",
    "d=0.2\n",
    "iter_freqs = [\n",
    "    ('fr', 1, 3),\n",
    "    ('fr', 4, 6)\n",
    "]\n",
    "condition = 'All'\n",
    "keep_feat = ['envelop']\n",
    "remove_feat = ['lipaparature']\n",
    "features = ['envelop','jawaopening','lipaparature','lipProtrusion','TTCD','TMCD','TBCD']\n",
    "remove_first = 0.5 #seconds\n",
    "channel_names = GA_epoches[0].ch_names\n",
    "eeg_chan = GA_epoches[0].ch_names[0:59]\n",
    "#######################################\n",
    "indices = []\n",
    "b = (np.repeat(59,59),np.arange(0,59))\n",
    "indices.append(b)\n",
    "b = (np.repeat(60,59),np.arange(0,59))\n",
    "indices.append(b)\n",
    "b = (np.repeat(59,1),np.repeat(60,1))\n",
    "#indices.append(b)\n",
    "\n",
    "INDEX = []\n",
    "b=0\n",
    "for idx in range(0,len(indices)):\n",
    "    a = np.arange(b,b+len(indices[idx][0]))\n",
    "    INDEX.append(a)\n",
    "    b = b+len(a)\n",
    "\n",
    "indices = np.concatenate((indices),axis=1)\n",
    "indices = (indices[0],indices[1])\n",
    "#######################################  \n",
    "\n",
    "eeg = partialCoherence_preprocess_delay(GA_epoches[s],remove_first,d + 0.5,trial_len,eeg_chan,condition)\n",
    "envelop = partialCoherence_preprocess_delay(GA_epoches[s],remove_first,d + 0.5,trial_len,keep_feat,condition)\n",
    "lipaparature = partialCoherence_preprocess_delay(GA_epoches[s],remove_first,d + 0.5,trial_len,remove_feat,condition) \n",
    "\n",
    "c = np.concatenate((eeg,envelop,lipaparature),axis=1)\n",
    "print(c.shape)\n",
    "print(fmin)\n",
    "print(fmax)\n",
    "coh = get_coherence(c,400,fmin,fmax,indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conXY = coh[INDEX[0],:]\n",
    "a = plt.plot(conXY[:,0]) # plotting by columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = ['All']\n",
    "indices = (np.repeat([np.arange(59,len(features)+59)],59),np.tile(np.arange(0,59),len(features)))   \n",
    "\n",
    "extra_channels = ['envelop','jawaopening','lipaparature','lipProtrusion','TTCD','TMCD','TBCD']\n",
    "eeg_channles = GA_epoches[0].ch_names[0:59]\n",
    "event_id = {'Hyper': 1,'Normal': 2,'Hypo': 3}\n",
    "ch_types = np.repeat('eeg', len(features)+59)\n",
    "ch_names = np.hstack((eeg_channles,features))        \n",
    "info = mne.create_info(ch_names = ch_names.tolist(),ch_types = ch_types,sfreq = GA_epoches[0].info['sfreq'])\n",
    "ch_names = np.setdiff1d(extra_channels,features)\n",
    "c = coherence_preprocess_delay(GA_epoches[s],remove_first,d+0.5,trial_len,extra_channels,eeg_channles,condition)\n",
    "coh2 = get_coherence(c,400,fmin,fmax,indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = np.split(coh2[:,0], len(features))\n",
    "a = plt.plot(cc[0]) # plotting by columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.concatenate((eeg,envelop,lipaparature),axis=1)\n",
    "coh = get_coherence(c,400,fmin,fmax,indices)\n",
    "conXY = coh[INDEX[0],:]\n",
    "conXR = coh[INDEX[1],:]\n",
    "conRY = coh[INDEX[2],:][0]\n",
    "a = plt.plot(conXY[:,0]) # plotting by columns\n",
    "a = plt.plot(conXR[:,0]) # plotting by columns\n",
    "print(conRY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=0\n",
    "epochs = GA_epoches[s].copy()\n",
    "eeg = epochs.copy().pick_channels(eeg_channles)\n",
    "speech = epochs.copy().pick_channels(extra_channels)\n",
    "\n",
    "E = eeg.copy().crop(d+remove_first,d+remove_first+trial_len)\n",
    "S = speech.copy().crop(0.5+remove_first,0.5+remove_first+trial_len)\n",
    "\n",
    "events = E.events\n",
    "sfreq = E.info['sfreq']    \n",
    "C = np.concatenate((E.get_data(),S.get_data()),axis=1)\n",
    "epochs = mne.EpochsArray(C, info, E.events, 0,event_id)\n",
    "c = epochs.get_data()\n",
    "\n",
    "ch_names = np.hstack((E.ch_names,S.ch_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A = C.mean(axis=0)\n",
    "#a = plt.plot(A[2,:]) # plotting by columns\n",
    "A = c.mean(axis=0)\n",
    "a = plt.plot(A[59,:]) # plotting by columns\n",
    "\n",
    "#a = epochs.copy().pick_channels(['AF7']).get_data()\n",
    "#A = a.mean(axis=0)\n",
    "#a = plt.plot(A[0,:]) # plotting by columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(GA_epoches[s].ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.concatenate((eeg,envelop,lipaparature),axis=1)\n",
    "coh = get_coherence(c,400,fmin,fmax,indices)\n",
    "conXY = coh[INDEX[1],:]\n",
    "conXR = coh[INDEX[0],:]\n",
    "conRY = coh[INDEX[2],:][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = plt.plot(conXY[:,0]) # plotting by columns\n",
    "a = plt.plot(conXR[:,0]) # plotting by columns\n",
    "print(conRY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = plt.plot(conXY[0:59,0]) # plotting by columns\n",
    "a = plt.plot(conXY[59:118,0]) # plotting by columns\n",
    "print(conXY[118,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keep_feat1= np.append(eeg_chan,keep_feat)\n",
    "\n",
    "envelop = partialCoherence_preprocess_delay(GA_epoches[s],remove_first,d + 0.5,trial_len,channel_names,\n",
    "                                           keep_feat1,condition)\n",
    "\n",
    "remove_feat1= np.append(eeg_chan,remove_feat)\n",
    "lipaparature = partialCoherence_preprocess_delay(GA_epoches[s],remove_first,d + 0.5,trial_len,channel_names,\n",
    "                                                 remove_feat1,condition)                \n",
    "\n",
    "conXY = get_coherence(envelop,400,fmin,fmax,indicesXY)\n",
    "conXR = get_coherence(lipaparature,400,fmin,fmax,indicesXR)\n",
    "\n",
    "c = np.dstack((envelop[:,59,:],lipaparature[:,59,:]))\n",
    "c = np.swapaxes(c,1,2)\n",
    "conRY = get_coherence(c,400,fmin,fmax,indicesRY)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = plt.plot(conXY[:,0]) # plotting by columns\n",
    "a = plt.plot(conXR[:,0]) # plotting by columns\n",
    "print(conRY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg = partialCoherence_preprocess_delay(GA_epoches[s],remove_first,d + 0.5,trial_len,channel_names,\n",
    "                                            eeg_chan,condition)\n",
    "keep_feat = ['envelop']\n",
    "\n",
    "envelop = partialCoherence_preprocess_delay(GA_epoches[s],remove_first,d + 0.5,trial_len,channel_names,\n",
    "                                           keep_feat,condition)\n",
    "remove_feat = ['lipaparature']\n",
    "\n",
    "lipaparature = partialCoherence_preprocess_delay(GA_epoches[s],remove_first,d + 0.5,trial_len,channel_names,\n",
    "                                                 remove_feat,condition)                \n",
    "\n",
    "c = np.concatenate((eeg,envelop),axis=1)\n",
    "conXY = get_coherence(c,400,fmin,fmax,indicesXY)\n",
    "c = np.concatenate((eeg,lipaparature),axis=1)\n",
    "conXR = get_coherence(c,400,fmin,fmax,indicesXR)\n",
    "\n",
    "c = np.concatenate((envelop,lipaparature),axis=1)\n",
    "conRY = get_coherence(c,400,fmin,fmax,indicesRY)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = plt.plot(conXY[:,0]) # plotting by columns\n",
    "a = plt.plot(conXR[:,0]) # plotting by columns\n",
    "print(conRY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bandpass filter epoches and save as fieldtrip format for partial coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iter_freqs = [\n",
    "    ('fr', 1, 3),\n",
    "    #('fr', 2, 4),\n",
    "    #('fr', 3, 5),\n",
    "    ('fr', 4, 6)\n",
    "    #('fr', 5, 7),\n",
    "    #('fr', 6, 8),\n",
    "    #('fr', 7, 9),\n",
    "    #('fr', 8, 10),\n",
    "    #('fr', 9, 11),\n",
    "    #('fr', 10, 12)\n",
    "]\n",
    "\n",
    "save_path = data_path +'/python/data/partialCoh/partialCoh-trailLen-' +str(trial_len)+'-removedFirst-'+ str(remove_first)\n",
    "\n",
    "features = ['envelop','jawaopening','lipaparature','lipProtrusion','TTCD','TMCD','TBCD']\n",
    "condition = ['Hyper','Normal','Hypo','All']\n",
    "delay = np.arange(0,1.1,0.1)\n",
    "\n",
    "\n",
    "extra_channels = ['envelop','jawaopening','lipaparature','lipProtrusion','TTCD','TMCD','TBCD']\n",
    "eeg_channles = np.setdiff1d(GA_epoches[0].ch_names, extra_channels)\n",
    "event_id = {'Hyper': 1,'Normal': 2,'Hypo': 3}\n",
    "ch_types = np.repeat('eeg', len(features)+59)\n",
    "ch_names = np.hstack((eeg_channles,features))        \n",
    "info = mne.create_info(ch_names = ch_names.tolist(),ch_types = ch_types,sfreq = GA_epoches[0].info['sfreq'])\n",
    "ch_names = np.setdiff1d(extra_channels,features)\n",
    "        \n",
    "for s in range(0,len(subject_name)):\n",
    "    for d in delay:   \n",
    "        for c in condition:\n",
    "            for fr in range(0,len(iter_freqs)):\n",
    "                b = str(iter_freqs[fr][0])+ '-'+str(iter_freqs[fr][1])+'-'+str(iter_freqs[fr][2])+'Hz'\n",
    "\n",
    "                fmin = iter_freqs[fr][1]\n",
    "                fmax = iter_freqs[fr][2]\n",
    "                a = listen_italian_functions.partialCoherence_preprocess_delay(GA_epoches[s],remove_first,d,\n",
    "                                                                               trial_len,extra_channels,eeg_channles,\n",
    "                                                                               info,ch_names,event_id,fmin,fmax,c)   \n",
    "    \n",
    "                d = d.round(decimals=1)\n",
    "                scipy.io.savemat(save_path+'s-'+'condition-'+c+'-delay-'+str(d)+'-'+b+'-' +subject_name[s],a)\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
